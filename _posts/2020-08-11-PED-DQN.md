---
layout:     post
title:      Inducing Cooperation through Reward Reshaping based on Peer Evaluations in Deep Multi-Agent Reinforcement Learning
subtitle:   Reading notes
date:       2020-08-11
author:     Haoxin
header-img: img/post-bg-coffee.jpeg
catalog: true
tags:
    - Multi-Agent Reinforcement Learning
    - Deep Reinforcement Learning
    - Cooperation
---

## Abstract  
This paper proposed a **deep reinforcement learning** algorithm for **semi-cooperative** multi-agent tasks.  
*Here, the word "semi-cooperative" means agents are equipped with their separate reward functions, yet with some willingness to cooperate.*  

The algorithm in the paper is called Peer Evaluation-based Dual DQN (PED-DQN), it proposes to give *peer evaluation signals* to observed agents.  
*Here, "peer evaluation signals" quantify how agents strategically value a certain transition and this could be regarded as agents' 'selfish'.*  


## Introduction  
The translation from single-agent to multi-agent settings is difficult, the authors explain this from this aspect:  
> *"These simultaneous policy updates make the environment’s transition probabilities non-stationary, which in turn makes learning difficult for the agents because a slight change in one’s policy may cause another agent’s policy to perform sub-optimally."*  

### Fully cooperative cases  
Agents agree to cooperate unconditionally, e.g. being controlled by a single authority. In these cases, a set of agents usually learn to maximize a global  reward and thus the reward function itself can naturally induce a certain level of cooperation.  
*Here, 'Global reward' means that each agent receive the same (scalar) reward value for each step.*  
所以，完全合作的情况是指所有agent都无条件合作，受中央同一控制，目标是最大化统一的一个global reward。  
### Semi-cooperative
在其他的情况中，agent会考虑自身的利益(interests)，但是也能从合作中获利，这种情况就称为“semi-cooperative“：  
> Agents may each have its own separate reward function, but is willing to cooperate if an incentive for cooperation is appropriately provided.  
> Semi-cooperative tasks are those with separate per-agent reward functions but whose agents may nonetheless benefit from cooperation.  

The key challenge in semi-cooperative tasks is: we use separate reward functions to represent the selfishness of each agent, yet this often results in agent's choice of non-cooperative actions.  
这句话的意思是，我们通常用独立的reward function来表示每个agent的selfishness，但是这通常会导致agent选择非合作的动作，这也是半合作情况中的关键问题。  
紧接着，作者提出了他们的目标：  
> The **goal** is for the agents to find cooperative policies that will maximize the *social welfare* which is defined as the sum of the rewards of each agent across the entire episode.  

简言之，作者整篇文章的目标将会是实现社会福利最大化。  

------

